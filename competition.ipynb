{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Transform csv to pkl file\nimport pandas as pd\nimport os\n\ncsv_train = pd.read_csv(\"../input/sdf-dsi-2022/train.csv\")\ncsv_test = pd.read_csv(\"../input/sdf-dsi-2022/test.csv\")\n\ncsv_train.to_pickle(\"/\".join((os.getcwd(), \"train.pkl\")))\ncsv_test.to_pickle(\"/\".join((os.getcwd(), \"test.pkl\")))","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:39:51.063102Z","iopub.execute_input":"2022-11-24T02:39:51.063510Z","iopub.status.idle":"2022-11-24T02:41:11.292700Z","shell.execute_reply.started":"2022-11-24T02:39:51.063476Z","shell.execute_reply":"2022-11-24T02:41:11.291669Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"!pip install dabl\nimport dabl","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport os\n\n# train_raw = pd.read_pickle(\"/\".join((os.getcwd(), \"train.pkl\")))\n# test_raw = pd.read_pickle(\"/\".join((os.getcwd(), \"test.pkl\")))\nwith open(\"/\".join((os.getcwd(), \"train.pkl\")), 'rb') as f:\n    train_raw = pickle.load(f)\n\nwith open(\"/\".join((os.getcwd(), \"test.pkl\")), 'rb') as f:\n    test_raw = pickle.load(f)    \n    \ntrain = train_raw.drop(columns=[\"transaction_id\", \n                            \"memo\", \n                            \"fee_account\",  \n                            \"account\",\n                            \"memo_type\",\n                            \"prior_closed_at\",\n                            \"time_bounds\",\n                            \"current_ledger_sequence\",\n                            \"prior_ledger_sequence\",\n                            \"operation_types\",\n                            \"surge_price_ind\"])\n# train = train.fillna(0)\ntrain_label = train.fee_charged\ntrain_data = train.drop(columns=\"fee_charged\")\n\npreprocessor = dabl.EasyPreprocessor()\ntrain_data = dabl.clean(train_data)\npreprocessor.fit(train_data)\ntrain_data = preprocessor(train_data)\n\n\ntest = test_raw.drop(columns=[\"transaction_id\", \n                          \"prior_ledger_sequence\",\n                          \"prior_closed_at\",\n                          \"time_bounds\",\n                          \"fee_account\",\n                          \"operation_types\",\n                          \"memo\",\n                          \"memo_type\",\n                          \"account\"])\n# test = test.fillna(0)\n\ntest = dabl.clean(test)\npreprocessor.fit(test)\ntest = preprocessor(test)\n\nattributes_train = train_data.columns\nattributes_test = test.columns\n\nif not sorted(attributes_train) == sorted(attributes_test):\n    print(sorted(attributes_train))\n    print(sorted(attributes_test))\n    assert Exception(\"attributes do not match!\")\n\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:45:02.653137Z","iopub.execute_input":"2022-11-24T02:45:02.653820Z","iopub.status.idle":"2022-11-24T02:45:21.011495Z","shell.execute_reply.started":"2022-11-24T02:45:02.653782Z","shell.execute_reply":"2022-11-24T02:45:21.010294Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   prior_successful_transaction_count  prior_failed_transaction_count  \\\n0                                 381                             173   \n1                                 174                             338   \n2                                 205                             319   \n3                                 244                             207   \n4                                 196                             197   \n\n   prior_operation_count  prior_successful_operation_count  \\\n0                    960                               770   \n1                    950                               601   \n2                    988                               626   \n3                    921                               690   \n4                    914                               709   \n\n   prior_max_fee_charged  prior_min_fee_charged  prior_avg_fee_charged  \\\n0                  10000                    100             173.285199   \n1                  10000                    100             185.546875   \n2                  10000                    100             188.549618   \n3                  10000                    100             204.212860   \n4                  10000                    100             232.569975   \n\n   transaction_operation_count  max_fee_bid  new_max_fee_bid  \n0                            1          110              0.0  \n1                            1          110              0.0  \n2                            1          110              0.0  \n3                            1          110              0.0  \n4                            1          110              0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prior_successful_transaction_count</th>\n      <th>prior_failed_transaction_count</th>\n      <th>prior_operation_count</th>\n      <th>prior_successful_operation_count</th>\n      <th>prior_max_fee_charged</th>\n      <th>prior_min_fee_charged</th>\n      <th>prior_avg_fee_charged</th>\n      <th>transaction_operation_count</th>\n      <th>max_fee_bid</th>\n      <th>new_max_fee_bid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>381</td>\n      <td>173</td>\n      <td>960</td>\n      <td>770</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>173.285199</td>\n      <td>1</td>\n      <td>110</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>174</td>\n      <td>338</td>\n      <td>950</td>\n      <td>601</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>185.546875</td>\n      <td>1</td>\n      <td>110</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>205</td>\n      <td>319</td>\n      <td>988</td>\n      <td>626</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>188.549618</td>\n      <td>1</td>\n      <td>110</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>244</td>\n      <td>207</td>\n      <td>921</td>\n      <td>690</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>204.212860</td>\n      <td>1</td>\n      <td>110</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>196</td>\n      <td>197</td>\n      <td>914</td>\n      <td>709</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>232.569975</td>\n      <td>1</td>\n      <td>110</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom collections import defaultdict\n\ntrain_label_data = train_label.to_numpy()\n# I am going to give 50 bins\nbins = np.zeros((50, ))\ncnts = defaultdict(list)\nfor i, data in enumerate(train_label_data):\n    index = min(49, data // 100)\n    bins[index] += 1\n    cnts[index].append(i)\nplt.bar(range(len(bins)), bins)\nplt.yscale(\"log\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:46:05.919664Z","iopub.execute_input":"2022-11-24T02:46:05.920862Z","iopub.status.idle":"2022-11-24T02:46:20.089057Z","shell.execute_reply.started":"2022-11-24T02:46:05.920820Z","shell.execute_reply":"2022-11-24T02:46:20.088029Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"downsample_limit = int(np.median(bins[1:-1]))\nprint(downsample_limit)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:46:27.175242Z","iopub.execute_input":"2022-11-24T02:46:27.176238Z","iopub.status.idle":"2022-11-24T02:46:27.183394Z","shell.execute_reply.started":"2022-11-24T02:46:27.176199Z","shell.execute_reply":"2022-11-24T02:46:27.182296Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"3677\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Build network","metadata":{}},{"cell_type":"code","source":"!pip install pytorch-tabnet","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:47:36.632336Z","iopub.execute_input":"2022-11-24T02:47:36.632973Z","iopub.status.idle":"2022-11-24T02:47:48.658663Z","shell.execute_reply.started":"2022-11-24T02:47:36.632936Z","shell.execute_reply":"2022-11-24T02:47:48.657456Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting pytorch-tabnet\n  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m171.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.11.0)\nRequirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.0.2)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.21.6)\nRequirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.7.3)\nRequirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.64.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.1.1)\nInstalling collected packages: pytorch-tabnet\nSuccessfully installed pytorch-tabnet-4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from pytorch_tabnet.tab_model import TabNetRegressor\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\nimport torch\nimport torch.nn as nn\nimport copy\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndef pretrain(pretrained_data, downsample=False):\n    if downsample:\n        indices = list()\n        for key in cnts:\n            sample_indices = np.random.choice(cnts[key], size=downsample_limit)\n            indices.extend(sample_indices.tolist())\n        indices = np.asarray(indices)\n        pretrained_data = pretrained_data[indices]\n    unsupervised_model = TabNetPretrainer(\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-2),\n    mask_type=\"entmax\",\n    verbose=0)\n    indices = int(len(pretrained_data) * 0.8)\n    unsupervised_model.fit(X_train=pretrained_data[:indices],\n                          eval_set=[pretrained_data[indices:]],\n                          pretraining_ratio=0.8,\n                          num_workers=1)\n    print(\"pretrain completed!\")\n    return unsupervised_model\n\ndef train(batched_train_data, \n          batched_train_label, \n          batched_eval_data,\n          batched_eval_label,\n          continue_training=False,\n          unsupervised_model=None,\n          base_model=None):\n    if len(batched_train_label.shape) == 1:\n        batched_train_label = batched_train_label.reshape(-1, 1)\n    if len(batched_val_label.shape) == 1:\n        batched_eval_label = batched_eval_label.reshape(-1, 1)\n    if continue_training:\n        if base_model is None:\n            assert Exception(\"Invalid checkpoint!\")\n        base_model.fit(X_train=batched_train_data,\n           y_train=batched_train_label,\n           eval_set=[(batched_eval_data, batched_eval_label)],\n           eval_name=[\"valid\"],\n           eval_metric=[\"rmse\"],\n           from_unsupervised=unsupervised_model,\n           augmentations=None)\n        reg = copy.deepcopy(base_model)\n    else:\n        reg = TabNetRegressor(\n        optimizer_fn=torch.optim.Adam,\n        optimizer_params=dict(lr=2e-3),\n        scheduler_params={\"step_size\": 10,\n                         \"gamma\": 0.9},\n        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n        mask_type=\"entmax\",\n        verbose=0)\n        reg.fit(X_train=batched_train_data,\n               y_train=batched_train_label,\n               eval_set=[(batched_eval_data, batched_eval_label)],\n               eval_name=[\"valid\"],\n               eval_metric=[\"rmse\"],\n               from_unsupervised=unsupervised_model,\n               augmentations=None)\n    return reg\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:28:44.201198Z","iopub.execute_input":"2022-11-24T03:28:44.201668Z","iopub.status.idle":"2022-11-24T03:28:44.223602Z","shell.execute_reply.started":"2022-11-24T03:28:44.201630Z","shell.execute_reply":"2022-11-24T03:28:44.222463Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Reconstruct dataset and train","metadata":{}},{"cell_type":"code","source":"import copy\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nunsupervised_model = pretrain(train_data.to_numpy(), True)\nbase_model = None\nmodel_set = set()\nids = sorted(np.unique(train_raw.current_ledger_sequence.values))\nmerged_num_batches = len(ids) // 5\nfor i, trans_id in enumerate(ids):\n    if i == 0 or i == len(ids)-1:\n        continue\n    if i % merged_num_batches and i != 1:\n        continue_training = True\n    else:\n        continue_training = False\n        if base_model is not None:\n            model_set.add(copy.deepcopy(base_model))\n        base_model = None\n    prev_batched_data = train_data[train_raw.current_ledger_sequence == trans_id-1]\n    prev_batched_label = train_label[train_raw.current_ledger_sequence == trans_id-1].to_numpy()\n    batched_data = train_data[train_raw.current_ledger_sequence == trans_id]\n    info_prev_batched_data = prev_batched_data.loc[:, [\"max_fee_bid\", \n                                                       \"new_max_fee_bid\", \n                                                       \"transaction_operation_count\"]]\n    info_prev_batched_data = info_prev_batched_data.reset_index().drop(columns=\"index\")\n    info_batched_data = batched_data.loc[:, [\"prior_successful_transaction_count\", \n                                             \"prior_failed_transaction_count\", \n                                             \"prior_operation_count\", \n                                             \"prior_successful_operation_count\", \n                                             \"prior_max_fee_charged\", \n                                             \"prior_min_fee_charged\",\n                                             \"prior_avg_fee_charged\"]]\n    np_info_batched_data = np.tile(info_batched_data.to_numpy()[0], (len(prev_batched_label), 1))\n    info_batched_data = pd.DataFrame(np_info_batched_data, columns=[\"prior_successful_transaction_count\", \n                                             \"prior_failed_transaction_count\", \n                                             \"prior_operation_count\", \n                                             \"prior_successful_operation_count\", \n                                             \"prior_max_fee_charged\", \n                                             \"prior_min_fee_charged\",\n                                             \"prior_avg_fee_charged\"])\n    info_batched_data = info_batched_data.reset_index().drop(columns=\"index\")\n    final_batched_data = pd.concat((info_prev_batched_data, info_batched_data), axis=1).to_numpy()\n    indices = int(len(final_batched_data) * 0.8)\n    batched_train_data = final_batched_data[:indices]\n    batched_train_label = prev_batched_label[:indices]\n    batched_val_data = final_batched_data[indices:]\n    batched_val_label = prev_batched_label[indices:]\n    base_model = train(batched_train_data, \n                      batched_train_label, \n                      batched_val_data, \n                      batched_val_label, \n                      continue_training,\n                      unsupervised_model,\n                      base_model=base_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = np.zeros((len(model_set), len(test)))\n# preprocssing test set\nids = sorted(np.unique(test_raw.prior_ledger_sequence.values))\nfor trans_id in ids:\n    indices = test_raw.prior_ledger_sequence == trans_id\n    if trans_id == max(ids):\n        final_batched_data = test[indices].to_numpy()\n        for i, model in enumerate(model_set):\n            results[i, indices] = model.predict(final_batched_data)\n    else:\n        prev_batched_data = test[test_raw.prior_ledger_sequence == trans_id]\n        batched_data = test[train_raw.prior_ledger_sequence == trans_id+1]\n        info_prev_batched_data = prev_batched_data.loc[:, [\"max_fee_bid\", \n                                                           \"new_max_fee_bid\", \n                                                           \"transaction_operation_count\"]]\n        info_prev_batched_data = info_prev_batched_data.reset_index()\n        info_batched_data = batched_data.loc[:, [\"prior_successful_transaction_count\", \n                                                 \"prior_failed_transaction_count\", \n                                                 \"prior_operation_count\", \n                                                 \"prior_successful_operation_count\", \n                                                 \"prior_max_fee_charged\", \n                                                 \"prior_min_fee_charged\",\n                                                 \"prior_avg_fee_charged\"]]\n        info_batched_data = info_batched_data.reset_index()\n        final_batched_data = pd.concat((info_prev_batched_data, info_batched_data), axis=1)\n        for i, model in enumerate(model_set):\n            results[i, indices] = model.predict(final_batched_data.to_numpy())\npredict = results.mean(0)\npredict = np.where(predict < 100, 100, predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit final prediction","metadata":{}},{"cell_type":"code","source":"sample_submit = pd.read_csv(\"/\".join((\"../input/sdf-dsi-2022\", \"sample_submission.csv\")))\nsample_submit.predicted_fee = predict\nsample_submit.to_csv(\"./submission.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:57:35.739805Z","iopub.execute_input":"2022-11-24T03:57:35.740204Z","iopub.status.idle":"2022-11-24T03:57:44.038896Z","shell.execute_reply.started":"2022-11-24T03:57:35.740171Z","shell.execute_reply":"2022-11-24T03:57:44.037762Z"},"trusted":true},"execution_count":30,"outputs":[]}]}