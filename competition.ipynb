{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntrain_raw = pd.read_pickle(\"../input/stellar-blockchain-cvs-to-pkl/train.pkl\")\ntest_raw = pd.read_csv(\"../input/sdf-dsi-2022/test.csv\")\ntrain = train_raw.drop(columns=[\"transaction_id\", \n                            \"memo\", \n                            \"fee_account\",  \n                            \"account\",\n                            \"memo_type\",\n                            \"prior_closed_at\",\n                            \"time_bounds\",\n                            \"current_ledger_sequence\",\n                            \"prior_ledger_sequence\",\n                            \"operation_types\",\n                            \"surge_price_ind\"])\ntrain = train.fillna(0)\ntrain_label = train.fee_charged\ntrain_data = train.drop(columns=\"fee_charged\")\n\ntest = test_raw.drop(columns=[\"transaction_id\", \n                          \"prior_ledger_sequence\",\n                          \"prior_closed_at\",\n                          \"time_bounds\",\n                          \"fee_account\",\n                          \"operation_types\",\n                          \"memo\",\n                          \"memo_type\",\n                          \"account\"])\ntest = test.fillna(0)\nattributes_train = train_data.columns\nattributes_test = test.columns\n\nif not sorted(attributes_train) == sorted(attributes_test):\n    print(sorted(attributes_train))\n    print(sorted(attributes_test))\n    assert Exception(\"attributes do not match!\")\n\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T00:44:15.034994Z","iopub.execute_input":"2022-04-18T00:44:15.035485Z","iopub.status.idle":"2022-04-18T00:44:54.265375Z","shell.execute_reply.started":"2022-04-18T00:44:15.035449Z","shell.execute_reply":"2022-04-18T00:44:54.264516Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom collections import defaultdict\n\ntrain_label_data = train_label.to_numpy()\n# I am going to give 50 bins\nbins = np.zeros((50, ))\ncnts = defaultdict(list)\nfor i, data in enumerate(train_label_data):\n    index = min(49, data // 100)\n    bins[index] += 1\n    cnts[index].append(i)\nplt.bar(range(len(bins)), bins)\nplt.yscale(\"log\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T00:48:10.706685Z","iopub.execute_input":"2022-04-18T00:48:10.707060Z","iopub.status.idle":"2022-04-18T00:49:19.538030Z","shell.execute_reply.started":"2022-04-18T00:48:10.707022Z","shell.execute_reply":"2022-04-18T00:49:19.536920Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"downsample_limit = int(np.median(bins[1:-1]))\nprint(downsample_limit)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T00:53:47.841648Z","iopub.execute_input":"2022-04-18T00:53:47.841928Z","iopub.status.idle":"2022-04-18T00:53:47.848518Z","shell.execute_reply.started":"2022-04-18T00:53:47.841901Z","shell.execute_reply":"2022-04-18T00:53:47.847842Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Build network","metadata":{}},{"cell_type":"code","source":"!pip install pytorch-tabnet","metadata":{"execution":{"iopub.status.busy":"2022-04-18T00:45:55.502676Z","iopub.execute_input":"2022-04-18T00:45:55.503033Z","iopub.status.idle":"2022-04-18T00:46:10.070104Z","shell.execute_reply.started":"2022-04-18T00:45:55.502991Z","shell.execute_reply":"2022-04-18T00:46:10.069201Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from pytorch_tabnet.tab_model import TabNetRegressor\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\nimport torch\nimport torch.nn as nn\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndef pretrain(pretrained_data, downsample=False):\n    if downsample:\n        indices = list()\n        for key in cnts:\n            sample_indices = np.random.choice(cnts[key], size=downsample_limit)\n            indices.extend(sample_indices.tolist())\n        indices = np.asarray(indices)\n        pretrained_data = pretrained_data[indices]\n    unsupervised_model = TabNetPretrainer(\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-2),\n    mask_type=\"entmax\")\n    indices = int(len(pretrained_data) * 0.8)\n    unsupervised_model.fit(X_train=pretrained_data[:indices],\n                          eval_set=[pretrained_data[indices:]],\n                          pretraining_ratio=0.8)\n    print(\"pretrain completed!\")\n    return unsupervised_model\n\ndef train(batched_train_data, \n          batched_train_label, \n          batched_eval_data,\n          batched_eval_label,\n          continue_training=False,\n          unsupervised_model=None,\n          base_model=None):\n    if len(batched_train_label.shape) == 1:\n        batched_train_label = batched_train_label.reshape(-1, 1)\n    if len(batched_val_label.shape) == 1:\n        batched_eval_label = batched_eval_label.reshape(-1, 1)\n    if continue_training:\n        if base_model is None:\n            assert Exception(\"Invalid checkpoint!\")\n        base_model.fit(X_train=batched_train_data,\n           y_train=batched_train_label,\n           eval_set=[(batched_eval_data, batched_eval_label)],\n           eval_name=[\"valid\"],\n           from_unsupervised=None,\n           augmentations=aug)\n        reg = base_model\n    else:\n        reg = TabNetRegressor(\n        optimizer_fn=torch.optim.Adam,\n        optimizer_params=dict(lr=2e-2),\n        scheduler_params={\"step_size\": 10,\n                         \"gamma\": 0.9},\n        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n        mask_type=\"entmax\")\n        reg.fit(X_train=batched_train_data,\n               y_train=batched_train_label,\n               eval_set=[(batched_eval_data, batched_eval_label)],\n               eval_name=[\"valid\"],\n               eval_metric=[\"mse\"],\n               from_unsupervised=unsupervised_model,\n               augmentations=aug)\n    return reg\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T00:54:16.193011Z","iopub.execute_input":"2022-04-18T00:54:16.193322Z","iopub.status.idle":"2022-04-18T00:54:18.975750Z","shell.execute_reply.started":"2022-04-18T00:54:16.193285Z","shell.execute_reply":"2022-04-18T00:54:18.974716Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Reconstruct dataset","metadata":{}},{"cell_type":"code","source":"unsupervised_model = pretrain(train_data.to_numpy(), True)\nbase_model = None\nmodel_set = set()\nids = sorted(np.unique(train_raw.current_ledger_sequence.values))\nmerged_num_batches = len(ids) // 5\nfor i, trans_id in enumerate(ids):\n    if i == 0 or i == len(ids)-1:\n        continue\n    if i % merged_num_batches and i != 1:\n        continue_training = True\n    else:\n        continue_training = False\n        model_set.add(base_model)\n        base_model = None\n    prev_batched_data = train_data[train_raw.current_ledger_sequence == trans_id-1]\n    prev_batched_label = train_label[train_raw.current_ledger_sequence == trans_id-1].to_numpy()\n    batched_data = train_data[train_raw.current_ledger_sequence == trans_id]\n    info_prev_batched_data = prev_batched_data.loc[:, [\"max_fee_bid\", \n                                                       \"new_max_fee_bid\", \n                                                       \"transaction_operation_count\"]]\n    info_prev_batched_data = info_prev_batched_data.reset_index().drop(columns=\"index\")\n    info_batched_data = batched_data.loc[:, [\"prior_successful_transaction_count\", \n                                             \"prior_failed_transaction_count\", \n                                             \"prior_operation_count\", \n                                             \"prior_successful_operation_count\", \n                                             \"prior_max_fee_charged\", \n                                             \"prior_min_fee_charged\",\n                                             \"prior_avg_fee_charged\"]]\n    np_info_batched_data = np.tile(info_batched_data.to_numpy()[0], (len(prev_batched_label), 1))\n    info_batched_data = pd.DataFrame(np_info_batched_data, columns=[\"prior_successful_transaction_count\", \n                                             \"prior_failed_transaction_count\", \n                                             \"prior_operation_count\", \n                                             \"prior_successful_operation_count\", \n                                             \"prior_max_fee_charged\", \n                                             \"prior_min_fee_charged\",\n                                             \"prior_avg_fee_charged\"])\n    info_batched_data = info_batched_data.reset_index().drop(columns=\"index\")\n    final_batched_data = pd.concat((info_prev_batched_data, info_batched_data), axis=1).to_numpy()\n    indices = int(len(final_batched_data) * 0.8)\n    batched_train_data = final_batched_data[:indices]\n    batched_train_label = prev_batched_label[:indices]\n    batched_val_data = final_batched_data[indices:]\n    batched_val_label = prev_batched_label[indices:]\n    base_model = train(batched_train_data, \n                      batched_train_label, \n                      batched_val_data, \n                      batched_val_label, \n                      continue_training,\n                      unsupervised_model,\n                      base_model=base_model)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T17:09:25.830872Z","iopub.execute_input":"2022-04-17T17:09:25.831236Z","iopub.status.idle":"2022-04-17T18:03:50.664614Z","shell.execute_reply.started":"2022-04-17T17:09:25.831186Z","shell.execute_reply":"2022-04-17T18:03:50.662252Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"continue_training = False\nbase_model = None\nfinal_batched_data = train_data.to_numpy()\nindices = int(len(final_batched_data) * 0.8)\nbatched_train_data = final_batched_data[:indices]\nbatched_train_label = train_label.to_numpy()[:indices]\nbatched_val_data = final_batched_data[indices:]\nbatched_val_label = train_label.to_numpy()[indices:]\nbase_model = train(batched_train_data, \n                  batched_train_label, \n                  batched_val_data, \n                  batched_val_label, \n                  continue_training,\n                  unsupervised_model,\n                  base_model=base_model)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:48:05.245583Z","iopub.execute_input":"2022-04-17T18:48:05.245871Z","iopub.status.idle":"2022-04-17T19:49:54.731753Z","shell.execute_reply.started":"2022-04-17T18:48:05.245841Z","shell.execute_reply":"2022-04-17T19:49:54.730144Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"base_model = None\nmodel_set = set()\nids = sorted(np.unique(train_raw.current_ledger_sequence.values))\nmerged_num_batches = len(ids) // 5\nfor i, trans_id in enumerate(ids):\n    if i == 0 or i == len(ids)-1:\n        continue\n    if i % merged_num_batches and i != 1:\n        continue_training = True\n    else:\n        continue_training = False\n        model_set.add(base_model)\n        base_model = None\n    prev_batched_data = train_data[train_raw.current_ledger_sequence == trans_id-1]\n    prev_batched_label = train_label[train_raw.current_ledger_sequence == trans_id-1].to_numpy()\n    batched_data = train_data[train_raw.current_ledger_sequence == trans_id]\n    info_prev_batched_data = prev_batched_data.loc[:, [\"max_fee_bid\", \n                                                       \"new_max_fee_bid\", \n                                                       \"transaction_operation_count\"]]\n    info_prev_batched_data = info_prev_batched_data.reset_index().drop(columns=\"index\")\n    info_batched_data = batched_data.loc[:, [\"prior_successful_transaction_count\", \n                                             \"prior_failed_transaction_count\", \n                                             \"prior_operation_count\", \n                                             \"prior_successful_operation_count\", \n                                             \"prior_max_fee_charged\", \n                                             \"prior_min_fee_charged\",\n                                             \"prior_avg_fee_charged\"]]\n    np_info_batched_data = np.tile(info_batched_data.to_numpy()[0], (len(prev_batched_label), 1))\n    info_batched_data = pd.DataFrame(np_info_batched_data, columns=[\"prior_successful_transaction_count\", \n                                             \"prior_failed_transaction_count\", \n                                             \"prior_operation_count\", \n                                             \"prior_successful_operation_count\", \n                                             \"prior_max_fee_charged\", \n                                             \"prior_min_fee_charged\",\n                                             \"prior_avg_fee_charged\"])\n    info_batched_data = info_batched_data.reset_index().drop(columns=\"index\")\n    final_batched_data = pd.concat((info_prev_batched_data, info_batched_data), axis=1).to_numpy()\n    indices = int(len(final_batched_data) * 0.8)\n    batched_train_data = final_batched_data[:indices]\n    batched_train_label = prev_batched_label[:indices]\n    batched_val_data = final_batched_data[indices:]\n    batched_val_label = prev_batched_label[indices:]\n    base_model = train(batched_train_data, \n                      batched_train_label, \n                      batched_val_data, \n                      batched_val_label, \n                      continue_training,\n                      unsupervised_model,\n                      base_model=base_model)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:38:51.119472Z","iopub.execute_input":"2022-04-17T18:38:51.119790Z","iopub.status.idle":"2022-04-17T18:46:28.746804Z","shell.execute_reply.started":"2022-04-17T18:38:51.119760Z","shell.execute_reply":"2022-04-17T18:46:28.744634Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"results = np.zeros((len(model_set), len(test)))\n# preprocssing test set\nids = sorted(np.unique(test_raw.prior_ledger_sequence.values))\nfor trans_id in ids:\n    indices = test_raw.prior_ledger_sequence == trans_id\n    if trans_id == max(ids):\n        final_batched_data = test[indices].to_numpy()\n        for i, model in enumerate(model_set):\n            results[i, indices] = model.predict(final_batched_data)\n    else:\n        prev_batched_data = test[test_raw.prior_ledger_sequence == trans_id]\n        batched_data = test[train_raw.prior_ledger_sequence == trans_id+1]\n        info_prev_batched_data = prev_batched_data.loc[:, [\"max_fee_bid\", \n                                                           \"new_max_fee_bid\", \n                                                           \"transaction_operation_count\"]]\n        info_prev_batched_data = info_prev_batched_data.reset_index()\n        info_batched_data = batched_data.loc[:, [\"prior_successful_transaction_count\", \n                                                 \"prior_failed_transaction_count\", \n                                                 \"prior_operation_count\", \n                                                 \"prior_successful_operation_count\", \n                                                 \"prior_max_fee_charged\", \n                                                 \"prior_min_fee_charged\",\n                                                 \"prior_avg_fee_charged\"]]\n        info_batched_data = info_batched_data.reset_index()\n        final_batched_data = pd.concat((info_prev_batched_data, info_batched_data), axis=1)\n        for i, model in enumerate(model_set):\n            results[i, indices] = model.predict(final_batched_data.to_numpy())\npredict = results.mean(0)\npredict = predict.where(predict < 100, 100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit final prediction","metadata":{}},{"cell_type":"code","source":"sample_submit = pd.read_csv(file_path + \"sample_submission.csv\")\nsample_submit.predicted_fee = predict\nsample_submit.to_csv(\"./submission.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:23:08.261203Z","iopub.status.idle":"2022-04-16T20:23:08.261689Z","shell.execute_reply.started":"2022-04-16T20:23:08.261432Z","shell.execute_reply":"2022-04-16T20:23:08.261458Z"},"trusted":true},"execution_count":null,"outputs":[]}]}