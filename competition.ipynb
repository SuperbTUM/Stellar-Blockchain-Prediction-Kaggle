{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Transform csv to pkl file\nimport pandas as pd\nimport os\n\ncsv_train = pd.read_csv(\"../input/sdf-dsi-2022/train.csv\")\ncsv_test = pd.read_csv(\"../input/sdf-dsi-2022/test.csv\")\n\ncsv_train.to_pickle(\"/\".join((os.getcwd(), \"train.pkl\")))\ncsv_test.to_pickle(\"/\".join((os.getcwd(), \"test.pkl\")))","metadata":{"execution":{"iopub.status.busy":"2023-01-07T19:56:15.879629Z","iopub.execute_input":"2023-01-07T19:56:15.880584Z","iopub.status.idle":"2023-01-07T19:57:38.334346Z","shell.execute_reply.started":"2023-01-07T19:56:15.880471Z","shell.execute_reply":"2023-01-07T19:57:38.333149Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n  exec(code_obj, self.user_global_ns, self.user_ns)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"!pip install dabl\nimport dabl","metadata":{"execution":{"iopub.status.busy":"2023-01-07T20:05:45.791584Z","iopub.execute_input":"2023-01-07T20:05:45.792073Z","iopub.status.idle":"2023-01-07T20:05:57.945068Z","shell.execute_reply.started":"2023-01-07T20:05:45.791973Z","shell.execute_reply":"2023-01-07T20:05:57.944005Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: dabl in /opt/conda/lib/python3.7/site-packages (0.2.4)\nRequirement already satisfied: scikit-learn>=1.0 in /opt/conda/lib/python3.7/site-packages (from dabl) (1.0.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from dabl) (1.3.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from dabl) (1.7.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from dabl) (1.21.6)\nRequirement already satisfied: matplotlib>=3.4 in /opt/conda/lib/python3.7/site-packages (from dabl) (3.5.3)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (from dabl) (0.11.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.4->dabl) (1.4.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.4->dabl) (9.1.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.4->dabl) (3.0.9)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.4->dabl) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.4->dabl) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.4->dabl) (4.33.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.4->dabl) (21.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1.0->dabl) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1.0->dabl) (1.0.1)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->dabl) (2022.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.4->dabl) (4.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=3.4->dabl) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport os\n\n# train_raw = pd.read_pickle(\"/\".join((os.getcwd(), \"train.pkl\")))\n# test_raw = pd.read_pickle(\"/\".join((os.getcwd(), \"test.pkl\")))\nwith open(\"/\".join((os.getcwd(), \"train.pkl\")), 'rb') as f:\n    train_raw = pickle.load(f)\n\nwith open(\"/\".join((os.getcwd(), \"test.pkl\")), 'rb') as f:\n    test_raw = pickle.load(f)    \n\ntrain = train_raw.drop(columns=[ \n                            \"memo\", \n                            \"fee_account\",  \n                            \"account\",\n                            \"memo_type\",\n                            \"prior_closed_at\",\n                            \"time_bounds\",\n                            \"current_ledger_sequence\",\n                            \"prior_ledger_sequence\",\n                            \"operation_types\",\n                            \"surge_price_ind\"])\n\ntrain = train.fillna(0)\ntrain.to_pickle(\"/\".join((os.getcwd(), \"train_processed.pkl\")))\n\n \n# # train = train.fillna(0)\n# train_label = train.fee_charged\n# train_data = train.drop(columns=\"fee_charged\")\n\n\n# preprocessor = dabl.EasyPreprocessor()\n# train_data = dabl.clean(train_data)\n# preprocessor.fit(train_data)\n# train_data = preprocessor(train_data)\n\n\n# test = test_raw.drop(columns=[ \n#                           \"prior_ledger_sequence\",\n#                           \"prior_closed_at\",\n#                           \"time_bounds\",\n#                           \"fee_account\",\n#                           \"operation_types\",\n#                           \"memo\",\n#                           \"memo_type\",\n#                           \"account\"])\n# # test = test.fillna(0)\n\n# test.to_pickle(\"/\".join((os.getcwd(), \"test_processed.pkl\")))\n\n# test = dabl.clean(test)\n# preprocessor.fit(test)\n# test = preprocessor(test)\n\n# attributes_train = train_data.columns\n# attributes_test = test.columns\n\n# if not sorted(attributes_train) == sorted(attributes_test):\n#     print(sorted(attributes_train))\n#     print(sorted(attributes_test))\n#     assert Exception(\"attributes do not match!\")\n\n# train_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-07T20:19:00.433961Z","iopub.execute_input":"2023-01-07T20:19:00.434352Z","iopub.status.idle":"2023-01-07T20:19:19.897113Z","shell.execute_reply.started":"2023-01-07T20:19:00.434319Z","shell.execute_reply":"2023-01-07T20:19:19.895293Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport os\n\nwith open(\"/\".join((os.getcwd(), \"train_processed.pkl\")), 'rb') as f:\n    train = pickle.load(f)\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-07T20:19:26.379084Z","iopub.execute_input":"2023-01-07T20:19:26.379480Z","iopub.status.idle":"2023-01-07T20:19:28.049421Z","shell.execute_reply.started":"2023-01-07T20:19:26.379447Z","shell.execute_reply":"2023-01-07T20:19:28.048267Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       transaction_id  prior_successful_transaction_count  \\\n0  173351296747892736                                 381   \n1  173369889663148032                                 174   \n2  173326454658592768                                 205   \n3  173298812248768512                                 244   \n4  173292580250767360                                 196   \n\n   prior_failed_transaction_count  prior_operation_count  \\\n0                             173                    960   \n1                             338                    950   \n2                             319                    988   \n3                             207                    921   \n4                             197                    914   \n\n   prior_successful_operation_count  prior_max_fee_charged  \\\n0                               770                  10000   \n1                               601                  10000   \n2                               626                  10000   \n3                               690                  10000   \n4                               709                  10000   \n\n   prior_min_fee_charged  prior_avg_fee_charged  transaction_operation_count  \\\n0                    100             173.285199                            1   \n1                    100             185.546875                            1   \n2                    100             188.549618                            1   \n3                    100             204.212860                            1   \n4                    100             232.569975                            1   \n\n   max_fee_bid  new_max_fee_bid  fee_charged  \n0          110              0.0          100  \n1          110              0.0          100  \n2          110              0.0          100  \n3          110              0.0          100  \n4          110              0.0          100  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transaction_id</th>\n      <th>prior_successful_transaction_count</th>\n      <th>prior_failed_transaction_count</th>\n      <th>prior_operation_count</th>\n      <th>prior_successful_operation_count</th>\n      <th>prior_max_fee_charged</th>\n      <th>prior_min_fee_charged</th>\n      <th>prior_avg_fee_charged</th>\n      <th>transaction_operation_count</th>\n      <th>max_fee_bid</th>\n      <th>new_max_fee_bid</th>\n      <th>fee_charged</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>173351296747892736</td>\n      <td>381</td>\n      <td>173</td>\n      <td>960</td>\n      <td>770</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>173.285199</td>\n      <td>1</td>\n      <td>110</td>\n      <td>0.0</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>173369889663148032</td>\n      <td>174</td>\n      <td>338</td>\n      <td>950</td>\n      <td>601</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>185.546875</td>\n      <td>1</td>\n      <td>110</td>\n      <td>0.0</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>173326454658592768</td>\n      <td>205</td>\n      <td>319</td>\n      <td>988</td>\n      <td>626</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>188.549618</td>\n      <td>1</td>\n      <td>110</td>\n      <td>0.0</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>173298812248768512</td>\n      <td>244</td>\n      <td>207</td>\n      <td>921</td>\n      <td>690</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>204.212860</td>\n      <td>1</td>\n      <td>110</td>\n      <td>0.0</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>173292580250767360</td>\n      <td>196</td>\n      <td>197</td>\n      <td>914</td>\n      <td>709</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>232.569975</td>\n      <td>1</td>\n      <td>110</td>\n      <td>0.0</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data = train.values\n\ntrain_data = np.sort(train_data, axis=0)\ntrain_data = train_data[:, 1:]\ntrain_data = np.unique(train_data, axis=0)\ntrain_label = train_data[:, -1]","metadata":{"execution":{"iopub.status.busy":"2023-01-07T20:29:19.168938Z","iopub.execute_input":"2023-01-07T20:29:19.169989Z","iopub.status.idle":"2023-01-07T20:29:51.838245Z","shell.execute_reply.started":"2023-01-07T20:29:19.169946Z","shell.execute_reply":"2023-01-07T20:29:51.837160Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom collections import defaultdict\n\n# train_label_data = train_label.to_numpy()\n# I am going to give 50 bins\nbins = np.zeros((50, ))\ncnts = defaultdict(list)\nfor i, data in enumerate(train_label):\n    index = int(min(49, data // 100))\n    bins[index] += 1\n    cnts[index].append(i)\nplt.bar(range(len(bins)), bins)\nplt.yscale(\"log\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-07T20:31:05.232726Z","iopub.execute_input":"2023-01-07T20:31:05.233135Z","iopub.status.idle":"2023-01-07T20:31:06.142959Z","shell.execute_reply.started":"2023-01-07T20:31:05.233097Z","shell.execute_reply":"2023-01-07T20:31:06.141880Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"downsample_limit = int(np.median(bins[1:-1]))\nprint(downsample_limit)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T20:31:11.030427Z","iopub.execute_input":"2023-01-07T20:31:11.031128Z","iopub.status.idle":"2023-01-07T20:31:11.038332Z","shell.execute_reply.started":"2023-01-07T20:31:11.031086Z","shell.execute_reply":"2023-01-07T20:31:11.037139Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"171\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_data[:10])","metadata":{"execution":{"iopub.status.busy":"2023-01-07T20:33:51.896846Z","iopub.execute_input":"2023-01-07T20:33:51.897814Z","iopub.status.idle":"2023-01-07T20:33:51.904408Z","shell.execute_reply.started":"2023-01-07T20:33:51.897772Z","shell.execute_reply":"2023-01-07T20:33:51.903196Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[[  31.           19.          182.           32.          800.\n   100.          116.63585952    1.            0.            0.\n   100.        ]\n [  31.           19.          182.           32.          800.\n   100.          118.13403417    1.            0.            0.\n   100.        ]\n [  31.           19.          331.           32.          800.\n   100.          118.13403417    1.            0.            0.\n   100.        ]\n [  31.           31.          331.           32.          800.\n   100.          118.13403417    1.            0.            0.\n   100.        ]\n [  31.           31.          331.           32.          800.\n   100.          118.13403417    1.          100.            0.\n   100.        ]\n [  51.           31.          331.          114.          800.\n   100.          118.13403417    1.          100.            0.\n   100.        ]\n [  51.           31.          331.          114.         1000.\n   100.          118.13403417    1.          100.            0.\n   100.        ]\n [  51.           31.          331.          114.         1000.\n   100.          120.54455446    1.          100.            0.\n   100.        ]\n [  51.           32.          331.          114.         1000.\n   100.          120.54455446    1.          100.            0.\n   100.        ]\n [  51.           32.          353.          114.         1000.\n   100.          120.54455446    1.          100.            0.\n   100.        ]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Use GradientBoosting\nfrom sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, ExtraTreesRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\ngb_params = {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 25}\ngb_model = GradientBoostingRegressor(**gb_params).fit(train_data,train_label)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T20:38:25.840365Z","iopub.execute_input":"2023-01-07T20:38:25.840760Z","iopub.status.idle":"2023-01-07T20:38:33.336857Z","shell.execute_reply.started":"2023-01-07T20:38:25.840726Z","shell.execute_reply":"2023-01-07T20:38:33.335747Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"gb_model.train_score_","metadata":{"execution":{"iopub.status.busy":"2023-01-07T20:39:08.896985Z","iopub.execute_input":"2023-01-07T20:39:08.897432Z","iopub.status.idle":"2023-01-07T20:39:08.908605Z","shell.execute_reply.started":"2023-01-07T20:39:08.897396Z","shell.execute_reply":"2023-01-07T20:39:08.907592Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"array([5.60417349e+08, 4.55080918e+08, 3.69499856e+08, 3.00159296e+08,\n       2.43811771e+08, 1.98076639e+08, 1.61113830e+08, 1.30965756e+08,\n       1.06531016e+08, 8.67325167e+07, 7.05910895e+07, 5.75054287e+07,\n       4.68941940e+07, 3.82580825e+07, 3.12568517e+07, 2.55877237e+07,\n       2.09914264e+07, 1.72593592e+07, 1.42197237e+07, 1.17460305e+07,\n       9.73818403e+06, 8.10915159e+06, 6.78680881e+06, 5.71475493e+06,\n       4.84497086e+06])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Build network","metadata":{}},{"cell_type":"code","source":"!pip install pytorch-tabnet","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:47:36.632336Z","iopub.execute_input":"2022-11-24T02:47:36.632973Z","iopub.status.idle":"2022-11-24T02:47:48.658663Z","shell.execute_reply.started":"2022-11-24T02:47:36.632936Z","shell.execute_reply":"2022-11-24T02:47:48.657456Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting pytorch-tabnet\n  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m171.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.11.0)\nRequirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.0.2)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.21.6)\nRequirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.7.3)\nRequirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.64.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.1.1)\nInstalling collected packages: pytorch-tabnet\nSuccessfully installed pytorch-tabnet-4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from pytorch_tabnet.tab_model import TabNetRegressor\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\nimport torch\nimport torch.nn as nn\nimport copy\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndef pretrain(pretrained_data, downsample=False):\n    if downsample:\n        indices = list()\n        for key in cnts:\n            sample_indices = np.random.choice(cnts[key], size=downsample_limit)\n            indices.extend(sample_indices.tolist())\n        indices = np.asarray(indices)\n        pretrained_data = pretrained_data[indices]\n    unsupervised_model = TabNetPretrainer(\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-2),\n    mask_type=\"entmax\",\n    verbose=0)\n    indices = int(len(pretrained_data) * 0.8)\n    unsupervised_model.fit(X_train=pretrained_data[:indices],\n                          eval_set=[pretrained_data[indices:]],\n                          pretraining_ratio=0.8,\n                          num_workers=1)\n    print(\"pretrain completed!\")\n    return unsupervised_model\n\ndef train(batched_train_data, \n          batched_train_label, \n          batched_eval_data,\n          batched_eval_label,\n          continue_training=False,\n          unsupervised_model=None,\n          base_model=None):\n    if len(batched_train_label.shape) == 1:\n        batched_train_label = batched_train_label.reshape(-1, 1)\n    if len(batched_val_label.shape) == 1:\n        batched_eval_label = batched_eval_label.reshape(-1, 1)\n    if continue_training:\n        if base_model is None:\n            assert Exception(\"Invalid checkpoint!\")\n        base_model.fit(X_train=batched_train_data,\n           y_train=batched_train_label,\n           eval_set=[(batched_eval_data, batched_eval_label)],\n           eval_name=[\"valid\"],\n           eval_metric=[\"rmse\"],\n           from_unsupervised=unsupervised_model,\n           augmentations=None)\n        reg = copy.deepcopy(base_model)\n    else:\n        reg = TabNetRegressor(\n        optimizer_fn=torch.optim.Adam,\n        optimizer_params=dict(lr=2e-3),\n        scheduler_params={\"step_size\": 10,\n                         \"gamma\": 0.9},\n        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n        mask_type=\"entmax\",\n        verbose=0)\n        reg.fit(X_train=batched_train_data,\n               y_train=batched_train_label,\n               eval_set=[(batched_eval_data, batched_eval_label)],\n               eval_name=[\"valid\"],\n               eval_metric=[\"rmse\"],\n               from_unsupervised=unsupervised_model,\n               augmentations=None)\n    return reg\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:28:44.201198Z","iopub.execute_input":"2022-11-24T03:28:44.201668Z","iopub.status.idle":"2022-11-24T03:28:44.223602Z","shell.execute_reply.started":"2022-11-24T03:28:44.201630Z","shell.execute_reply":"2022-11-24T03:28:44.222463Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Reconstruct dataset and train","metadata":{}},{"cell_type":"code","source":"import copy\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nunsupervised_model = pretrain(train_data.to_numpy(), True)\nbase_model = None\nmodel_set = set()\nids = sorted(np.unique(train_raw.current_ledger_sequence.values))\nmerged_num_batches = len(ids) // 5\nfor i, trans_id in enumerate(ids):\n    if i == 0 or i == len(ids)-1:\n        continue\n    if i % merged_num_batches and i != 1:\n        continue_training = True\n    else:\n        continue_training = False\n        if base_model is not None:\n            model_set.add(copy.deepcopy(base_model))\n        base_model = None\n    prev_batched_data = train_data[train_raw.current_ledger_sequence == trans_id-1]\n    prev_batched_label = train_label[train_raw.current_ledger_sequence == trans_id-1].to_numpy()\n    batched_data = train_data[train_raw.current_ledger_sequence == trans_id]\n    info_prev_batched_data = prev_batched_data.loc[:, [\"max_fee_bid\", \n                                                       \"new_max_fee_bid\", \n                                                       \"transaction_operation_count\"]]\n    info_prev_batched_data = info_prev_batched_data.reset_index().drop(columns=\"index\")\n    info_batched_data = batched_data.loc[:, [\"prior_successful_transaction_count\", \n                                             \"prior_failed_transaction_count\", \n                                             \"prior_operation_count\", \n                                             \"prior_successful_operation_count\", \n                                             \"prior_max_fee_charged\", \n                                             \"prior_min_fee_charged\",\n                                             \"prior_avg_fee_charged\"]]\n    np_info_batched_data = np.tile(info_batched_data.to_numpy()[0], (len(prev_batched_label), 1))\n    info_batched_data = pd.DataFrame(np_info_batched_data, columns=[\"prior_successful_transaction_count\", \n                                             \"prior_failed_transaction_count\", \n                                             \"prior_operation_count\", \n                                             \"prior_successful_operation_count\", \n                                             \"prior_max_fee_charged\", \n                                             \"prior_min_fee_charged\",\n                                             \"prior_avg_fee_charged\"])\n    info_batched_data = info_batched_data.reset_index().drop(columns=\"index\")\n    final_batched_data = pd.concat((info_prev_batched_data, info_batched_data), axis=1).to_numpy()\n    indices = int(len(final_batched_data) * 0.8)\n    batched_train_data = final_batched_data[:indices]\n    batched_train_label = prev_batched_label[:indices]\n    batched_val_data = final_batched_data[indices:]\n    batched_val_label = prev_batched_label[indices:]\n    base_model = train(batched_train_data, \n                      batched_train_label, \n                      batched_val_data, \n                      batched_val_label, \n                      continue_training,\n                      unsupervised_model,\n                      base_model=base_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = np.zeros((len(model_set), len(test)))\n# preprocssing test set\nids = sorted(np.unique(test_raw.prior_ledger_sequence.values))\nfor trans_id in ids:\n    indices = test_raw.prior_ledger_sequence == trans_id\n    if trans_id == max(ids):\n        final_batched_data = test[indices].to_numpy()\n        for i, model in enumerate(model_set):\n            results[i, indices] = model.predict(final_batched_data)\n    else:\n        prev_batched_data = test[test_raw.prior_ledger_sequence == trans_id]\n        batched_data = test[train_raw.prior_ledger_sequence == trans_id+1]\n        info_prev_batched_data = prev_batched_data.loc[:, [\"max_fee_bid\", \n                                                           \"new_max_fee_bid\", \n                                                           \"transaction_operation_count\"]]\n        info_prev_batched_data = info_prev_batched_data.reset_index()\n        info_batched_data = batched_data.loc[:, [\"prior_successful_transaction_count\", \n                                                 \"prior_failed_transaction_count\", \n                                                 \"prior_operation_count\", \n                                                 \"prior_successful_operation_count\", \n                                                 \"prior_max_fee_charged\", \n                                                 \"prior_min_fee_charged\",\n                                                 \"prior_avg_fee_charged\"]]\n        info_batched_data = info_batched_data.reset_index()\n        final_batched_data = pd.concat((info_prev_batched_data, info_batched_data), axis=1)\n        for i, model in enumerate(model_set):\n            results[i, indices] = model.predict(final_batched_data.to_numpy())\npredict = results.mean(0)\npredict = np.where(predict < 100, 100, predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit final prediction","metadata":{}},{"cell_type":"code","source":"sample_submit = pd.read_csv(\"/\".join((\"../input/sdf-dsi-2022\", \"sample_submission.csv\")))\nsample_submit.predicted_fee = predict\nsample_submit.to_csv(\"./submission.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:57:35.739805Z","iopub.execute_input":"2022-11-24T03:57:35.740204Z","iopub.status.idle":"2022-11-24T03:57:44.038896Z","shell.execute_reply.started":"2022-11-24T03:57:35.740171Z","shell.execute_reply":"2022-11-24T03:57:44.037762Z"},"trusted":true},"execution_count":30,"outputs":[]}]}